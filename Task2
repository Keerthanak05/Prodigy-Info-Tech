from transformers import GPT2LMHeadModel, GPT2Tokenizer

# Load the fine-tuned model and tokenizer
model = GPT2LMHeadModel.from_pretrained("./gpt2-finetuned")
tokenizer = GPT2Tokenizer.from_pretrained("./gpt2-finetuned")

# Set padding token for the tokenizer if not already set
tokenizer.pad_token = tokenizer.eos_token

# Define a prompt for generation
prompt = "Once upon a time in a distant land,"

# Encode the prompt text
input_ids = tokenizer(prompt, return_tensors="pt").input_ids

# Generate text
outputs = model.generate(
    input_ids=input_ids,
    max_length=100,         # Maximum length of the generated text
    temperature=0.7,        # Creativity (higher = more diverse)
    top_k=50,               # Top-k sampling
    num_return_sequences=1  # Number of sequences to generate
)

# Decode and print the generated text
generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(generated_text)
